# ensemble_prediction.py
# Multi-Region Ensemble System cho ph√°t hi·ªán g√£y x∆∞∆°ng tr√™n nhi·ªÅu v√πng c√°nh tay

import os
import cv2
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras.models import load_model
import matplotlib.cm as cm
from sklearn.metrics import confusion_matrix, classification_report
from tkinter import filedialog, messagebox
import tkinter as tk
import json
from datetime import datetime

class MultiRegionEnsemble:
    def __init__(self, models_config=None, input_shape=(224, 224), threshold=0.5):
        """
        Kh·ªüi t·∫°o Multi-Region Ensemble System
        
        Args:
            models_config: Dictionary config c√°c m√¥ h√¨nh theo v√πng
            input_shape: K√≠ch th∆∞·ªõc ƒë·∫ßu v√†o cho m√¥ h√¨nh CNN
            threshold: Ng∆∞·ª°ng x√°c su·∫•t ƒë·ªÉ x√°c ƒë·ªãnh g√£y x∆∞∆°ng
        """
        self.input_shape = input_shape
        self.threshold = threshold
        self.models = {}  # Dictionary l∆∞u tr·ªØ c√°c m√¥ h√¨nh
        self.model_weights = {}  # Tr·ªçng s·ªë cho t·ª´ng m√¥ h√¨nh
        self.regions = [
            'XR_HAND', 'XR_WRIST', 'XR_ELBOW', 
            'XR_FINGER', 'XR_FOREARM', 'XR_HUMERUS', 'XR_SHOULDER'
        ]
        
        if models_config:
            self.load_models_from_config(models_config)
        else:
            self.auto_discover_models()
    
    def auto_discover_models(self, base_dir="C:\\Users\\USER\\Documents\\coze"):
        """T·ª± ƒë·ªông t√¨m v√† t·∫£i c√°c m√¥ h√¨nh c√≥ s·∫µn"""
        print("üîç ƒêang t·ª± ƒë·ªông t√¨m ki·∫øm c√°c m√¥ h√¨nh...")
        
        model_types = ['densenet121', 'resnet50v2']
        found_models = []
        
        for region in self.regions:
            for model_type in model_types:
                model_paths = [
                    os.path.join(base_dir, "models", "res", f"{model_type}_{region}_best.h5"),
                    os.path.join(base_dir, "models", "den", f"{model_type}_{region}_best.h5"),
                    os.path.join(base_dir, "models", f"{model_type}_{region}_best.h5"),
                ]
                
                for path in model_paths:
                    if os.path.exists(path):
                        found_models.append({
                            'region': region,
                            'model_type': model_type,
                            'path': path,
                            'weight': 1.0  # Tr·ªçng s·ªë m·∫∑c ƒë·ªãnh
                        })
                        print(f"  ‚úÖ T√¨m th·∫•y: {region} - {model_type}")
                        break
        
        if not found_models:
            print("‚ùå Kh√¥ng t√¨m th·∫•y m√¥ h√¨nh n√†o!")
            return
        
        print(f"\nüìä T·ªïng c·ªông t√¨m th·∫•y {len(found_models)} m√¥ h√¨nh")
        self.load_selected_models(found_models)
    
    def load_selected_models(self, models_list):
        """T·∫£i c√°c m√¥ h√¨nh ƒë√£ ch·ªçn"""
        print(f"\nüîÑ ƒêang t·∫£i {len(models_list)} m√¥ h√¨nh...")
        
        for i, model_info in enumerate(models_list):
            try:
                model_key = f"{model_info['region']}_{model_info['model_type']}"
                print(f"  üì• ƒêang t·∫£i {model_key}...")
                
                model = load_model(model_info['path'])
                self.models[model_key] = {
                    'model': model,
                    'region': model_info['region'],
                    'model_type': model_info['model_type'],
                    'path': model_info['path']
                }
                self.model_weights[model_key] = model_info['weight']
                
                print(f"    ‚úÖ ƒê√£ t·∫£i th√†nh c√¥ng!")
                
            except Exception as e:
                print(f"    ‚ùå L·ªói khi t·∫£i {model_key}: {str(e)}")
        
        print(f"\nüéâ ƒê√£ t·∫£i th√†nh c√¥ng {len(self.models)} m√¥ h√¨nh!")
        self.print_loaded_models()
    
    def print_loaded_models(self):
        """In danh s√°ch c√°c m√¥ h√¨nh ƒë√£ t·∫£i"""
        print(f"\n{'='*60}")
        print("DANH S√ÅCH M√î H√åNH TRONG ENSEMBLE")
        print(f"{'='*60}")
        
        for model_key, model_info in self.models.items():
            weight = self.model_weights[model_key]
            print(f"üîπ {model_info['region']} - {model_info['model_type']} (weight: {weight:.2f})")
        
        print(f"{'='*60}")
    
    def set_model_weights(self, weights_dict):
        """Thi·∫øt l·∫≠p tr·ªçng s·ªë cho c√°c m√¥ h√¨nh"""
        for model_key, weight in weights_dict.items():
            if model_key in self.model_weights:
                self.model_weights[model_key] = weight
                print(f"üìä C·∫≠p nh·∫≠t tr·ªçng s·ªë {model_key}: {weight}")
    
    def preprocess_for_cnn(self, image):
        """Ti·ªÅn x·ª≠ l√Ω ·∫£nh cho m√¥ h√¨nh CNN"""
        if len(image.shape) == 3 and image.shape[2] == 3:
            image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            
        img_resized = cv2.resize(image, self.input_shape)
        img_normalized = img_resized / 255.0
        img_rgb = np.stack([img_normalized, img_normalized, img_normalized], axis=-1)
        img_tensor = np.expand_dims(img_rgb, axis=0)
        
        return img_tensor, img_normalized
    
    def predict_with_single_model(self, image, model_key):
        """D·ª± ƒëo√°n v·ªõi m·ªôt m√¥ h√¨nh ƒë∆°n l·∫ª"""
        model_info = self.models[model_key]
        model = model_info['model']
        
        # Ti·ªÅn x·ª≠ l√Ω ·∫£nh
        img_tensor, img_normalized = self.preprocess_for_cnn(image)
        
        # D·ª± ƒëo√°n
        prediction = model.predict(img_tensor, verbose=0)[0][0]
        
        # T·∫°o heatmap (simplified version)
        heatmap = self.generate_simple_heatmap(image, model, img_tensor)
        
        return prediction, heatmap
    
    def generate_simple_heatmap(self, original_image, model, img_tensor):
        """T·∫°o heatmap ƒë∆°n gi·∫£n (c√≥ th·ªÉ c·∫£i ti·∫øn th√™m v·ªõi Grad-CAM)"""
        try:
            # Simplified heatmap generation
            # C√≥ th·ªÉ implement Grad-CAM chi ti·∫øt h∆°n n·∫øu c·∫ßn
            prediction = model.predict(img_tensor, verbose=0)[0][0]
            
            # T·∫°o heatmap c∆° b·∫£n d·ª±a tr√™n prediction score
            h, w = original_image.shape[:2]
            heatmap = np.full((h, w), prediction * 0.5, dtype=np.float32)
            
            # Th√™m m·ªôt s·ªë noise ƒë·ªÉ l√†m cho heatmap th·ª±c t·∫ø h∆°n
            noise = np.random.normal(0, 0.1, (h, w))
            heatmap = np.clip(heatmap + noise, 0, 1)
            
            return heatmap
            
        except Exception as e:
            print(f"L·ªói t·∫°o heatmap: {str(e)}")
            return np.zeros((original_image.shape[0], original_image.shape[1]))
    
    def predict_ensemble(self, image, voting_method='weighted_average'):
        """
        D·ª± ƒëo√°n ensemble t·ª´ t·∫•t c·∫£ c√°c m√¥ h√¨nh
        
        Args:
            image: ·∫¢nh ƒë·∫ßu v√†o
            voting_method: Ph∆∞∆°ng ph√°p vote ('weighted_average', 'majority_vote', 'max_confidence')
        """
        if not self.models:
            raise ValueError("Kh√¥ng c√≥ m√¥ h√¨nh n√†o ƒë∆∞·ª£c t·∫£i!")
        
        predictions = {}
        heatmaps = {}
        
        # D·ª± ƒëo√°n v·ªõi t·ª´ng m√¥ h√¨nh
        for model_key in self.models.keys():
            pred, heatmap = self.predict_with_single_model(image, model_key)
            predictions[model_key] = pred
            heatmaps[model_key] = heatmap
        
        # K·∫øt h·ª£p predictions theo ph∆∞∆°ng ph√°p ƒë∆∞·ª£c ch·ªçn
        if voting_method == 'weighted_average':
            final_score = self.weighted_average_voting(predictions)
        elif voting_method == 'majority_vote':
            final_score = self.majority_voting(predictions)
        elif voting_method == 'max_confidence':
            final_score = self.max_confidence_voting(predictions)
        else:
            final_score = self.weighted_average_voting(predictions)
        
        # K·∫øt h·ª£p heatmaps
        combined_heatmap = self.combine_heatmaps(heatmaps)
        
        return final_score, combined_heatmap, predictions
    
    def weighted_average_voting(self, predictions):
        """Voting theo tr·ªçng s·ªë trung b√¨nh"""
        total_weight = sum(self.model_weights.values())
        weighted_sum = sum(
            pred * self.model_weights[model_key] 
            for model_key, pred in predictions.items()
        )
        return weighted_sum / total_weight
    
    def majority_voting(self, predictions):
        """Voting theo ƒëa s·ªë (binary)"""
        binary_preds = [1 if pred > self.threshold else 0 for pred in predictions.values()]
        return 1.0 if sum(binary_preds) > len(binary_preds) / 2 else 0.0
    
    def max_confidence_voting(self, predictions):
        """Voting theo confidence cao nh·∫•t"""
        return max(predictions.values())
    
    def combine_heatmaps(self, heatmaps):
        """K·∫øt h·ª£p c√°c heatmap theo tr·ªçng s·ªë"""
        if not heatmaps:
            return np.zeros((224, 224))
        
        # L·∫•y heatmap ƒë·∫ßu ti√™n l√†m base
        first_heatmap = list(heatmaps.values())[0]
        combined = np.zeros_like(first_heatmap)
        
        total_weight = sum(self.model_weights.values())
        
        for model_key, heatmap in heatmaps.items():
            weight = self.model_weights[model_key]
            combined += heatmap * (weight / total_weight)
        
        return np.clip(combined, 0, 1)
    
    def predict(self, image_path, voting_method='weighted_average'):
        """
        D·ª± ƒëo√°n ensemble cho m·ªôt ·∫£nh
        
        Args:
            image_path: ƒê∆∞·ªùng d·∫´n ·∫£nh
            voting_method: Ph∆∞∆°ng ph√°p vote
        """
        # ƒê·ªçc ·∫£nh
        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
        if image is None:
            raise ValueError(f"Kh√¥ng th·ªÉ ƒë·ªçc ·∫£nh t·ª´ {image_path}")
        
        # X√°c ƒë·ªãnh nh√£n th·∫≠t
        true_label = 1 if "abnormal" in image_path.lower() else 0
        
        # D·ª± ƒëo√°n ensemble
        ensemble_score, combined_heatmap, individual_preds = self.predict_ensemble(
            image, voting_method
        )
        
        # X√°c ƒë·ªãnh nh√£n d·ª± ƒëo√°n
        predicted_label = 1 if ensemble_score > self.threshold else 0
        confidence = ensemble_score if predicted_label == 1 else 1 - ensemble_score
        confidence_percent = confidence * 100
        
        return {
            'image_path': image_path,
            'image': image,
            'ensemble_score': ensemble_score,
            'individual_predictions': individual_preds,
            'predicted_label': predicted_label,
            'true_label': true_label,
            'confidence': confidence_percent,
            'heatmap': combined_heatmap,
            'voting_method': voting_method,
            'num_models': len(self.models)
        }
    
    def visualize_ensemble_result(self, result):
        """Tr·ª±c quan h√≥a k·∫øt qu·∫£ ensemble"""
        fig = plt.figure(figsize=(16, 10))
        
        # Layout: 2 rows, 4 columns
        # Row 1: Original image, Combined heatmap, Individual predictions chart
        # Row 2: Individual model details
        
        # ·∫¢nh g·ªëc
        ax1 = plt.subplot(2, 4, 1)
        ax1.imshow(result['image'], cmap='gray')
        ax1.set_title('·∫¢nh X-quang g·ªëc', fontsize=12, fontweight='bold')
        ax1.axis('off')
        
        # Combined heatmap
        ax2 = plt.subplot(2, 4, 2)
        ax2.imshow(result['image'], cmap='gray')
        heatmap_overlay = ax2.imshow(result['heatmap'], cmap='jet', alpha=0.6)
        ax2.set_title('Ensemble Heatmap', fontsize=12, fontweight='bold')
        ax2.axis('off')
        
        # Individual predictions chart
        ax3 = plt.subplot(2, 4, 3)
        model_names = [key.replace('_', '\n') for key in result['individual_predictions'].keys()]
        pred_values = list(result['individual_predictions'].values())
        
        colors = ['red' if p > self.threshold else 'green' for p in pred_values]
        bars = ax3.bar(range(len(pred_values)), pred_values, color=colors, alpha=0.7)
        ax3.axhline(y=self.threshold, color='black', linestyle='--', alpha=0.5)
        ax3.set_xticks(range(len(model_names)))
        ax3.set_xticklabels(model_names, rotation=45, ha='right', fontsize=8)
        ax3.set_ylabel('Prediction Score')
        ax3.set_title('Individual Model Predictions', fontsize=12, fontweight='bold')
        ax3.set_ylim(0, 1)
        
        # Add value labels on bars
        for bar, value in zip(bars, pred_values):
            ax3.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,
                    f'{value:.3f}', ha='center', va='bottom', fontsize=8)
        
        # Ensemble result summary
        ax4 = plt.subplot(2, 4, 4)
        ax4.axis('off')
        
        pred_text = "PH√ÅT HI·ªÜN G√ÉY X∆Ø∆†NG" if result['predicted_label'] == 1 else "KH√îNG PH√ÅT HI·ªÜN G√ÉY X∆Ø∆†NG"
        true_text = "G√ÉY X∆Ø∆†NG" if result['true_label'] == 1 else "B√åNH TH∆Ø·ªúNG"
        
        result_color = 'green' if result['predicted_label'] == result['true_label'] else 'red'
        
        summary_text = f"""
ENSEMBLE RESULT

Voting Method: {result['voting_method']}
Models Used: {result['num_models']}

DIAGNOSIS:
{pred_text}

Confidence: {result['confidence']:.1f}%
Ensemble Score: {result['ensemble_score']:.4f}

GROUND TRUTH:
{true_text}

Status: {'‚úì CORRECT' if result['predicted_label'] == result['true_label'] else '‚úó INCORRECT'}
        """
        
        ax4.text(0.1, 0.9, summary_text, transform=ax4.transAxes, 
                fontsize=10, verticalalignment='top',
                bbox=dict(boxstyle="round,pad=0.5", facecolor=result_color, alpha=0.1))
        
        # Model weights visualization
        ax5 = plt.subplot(2, 4, (5, 8))
        
        weights_text = "MODEL WEIGHTS & DETAILS:\n\n"
        for i, (model_key, pred_value) in enumerate(result['individual_predictions'].items()):
            region = model_key.split('_')[1] + '_' + model_key.split('_')[2]
            model_type = model_key.split('_')[0]
            weight = self.model_weights[model_key]
            
            status = "üî¥ FRACTURE" if pred_value > self.threshold else "üü¢ NORMAL"
            weights_text += f"{i+1}. {region} ({model_type})\n"
            weights_text += f"   Score: {pred_value:.4f} | Weight: {weight:.2f} | {status}\n\n"
        
        ax5.text(0.05, 0.95, weights_text, transform=ax5.transAxes,
                fontsize=9, verticalalignment='top', fontfamily='monospace',
                bbox=dict(boxstyle="round,pad=0.5", facecolor='lightgray', alpha=0.3))
        ax5.axis('off')
        
        plt.tight_layout()
        return fig
    
    def evaluate_ensemble(self, test_data, voting_methods=['weighted_average'], visualize=True, output_dir='ensemble_results'):
        """
        ƒê√°nh gi√° ensemble tr√™n test data
        
        Args:
            test_data: List c√°c ƒë∆∞·ªùng d·∫´n ·∫£nh ho·∫∑c th∆∞ m·ª•c
            voting_methods: List c√°c ph∆∞∆°ng ph√°p voting c·∫ßn test
            visualize: C√≥ l∆∞u visualization kh√¥ng
            output_dir: Th∆∞ m·ª•c output
        """
        if not os.path.exists(output_dir):
            os.makedirs(output_dir)
        
        results = {}
        
        for voting_method in voting_methods:
            print(f"\nüîÑ ƒê√°nh gi√° v·ªõi ph∆∞∆°ng ph√°p voting: {voting_method}")
            
            y_true = []
            y_pred = []
            detailed_results = []
            
            for i, image_path in enumerate(test_data):
                print(f"  üìã ƒêang x·ª≠ l√Ω {i+1}/{len(test_data)}: {os.path.basename(image_path)}")
                
                try:
                    result = self.predict(image_path, voting_method)
                    
                    y_true.append(result['true_label'])
                    y_pred.append(result['predicted_label'])
                    detailed_results.append(result)
                    
                    if visualize:
                        fig = self.visualize_ensemble_result(result)
                        save_path = os.path.join(
                            output_dir, 
                            f"{voting_method}_{os.path.basename(image_path).split('.')[0]}.png"
                        )
                        plt.savefig(save_path, dpi=150, bbox_inches='tight')
                        plt.close(fig)
                
                except Exception as e:
                    print(f"    ‚ùå L·ªói: {str(e)}")
            
            # T√≠nh metrics
            if len(set(y_true)) > 1:
                cm = confusion_matrix(y_true, y_pred)
                report = classification_report(y_true, y_pred, target_names=['Normal', 'Abnormal'])
                
                tn, fp, fn, tp = cm.ravel()
                accuracy = (tp + tn) / (tp + tn + fp + fn)
                precision = tp / (tp + fp) if (tp + fp) > 0 else 0
                recall = tp / (tp + fn) if (tp + fn) > 0 else 0
                f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0
                
                results[voting_method] = {
                    'accuracy': accuracy,
                    'precision': precision,
                    'recall': recall,
                    'f1_score': f1,
                    'confusion_matrix': cm,
                    'classification_report': report,
                    'detailed_results': detailed_results
                }
            else:
                results[voting_method] = {
                    'message': 'Ch·ªâ c√≥ m·ªôt lo·∫°i nh√£n',
                    'accuracy': sum(1 for t, p in zip(y_true, y_pred) if t == p) / len(y_true),
                    'detailed_results': detailed_results
                }
        
        # L∆∞u k·∫øt qu·∫£
        self.save_evaluation_results(results, output_dir)
        
        return results
    
    def save_evaluation_results(self, results, output_dir):
        """L∆∞u k·∫øt qu·∫£ ƒë√°nh gi√°"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # L∆∞u summary
        summary_file = os.path.join(output_dir, f'ensemble_evaluation_{timestamp}.txt')
        with open(summary_file, 'w', encoding='utf-8') as f:
            f.write("ENSEMBLE EVALUATION RESULTS\n")
            f.write("="*50 + "\n\n")
            
            for method, result in results.items():
                f.write(f"Voting Method: {method}\n")
                f.write("-" * 30 + "\n")
                
                if 'message' in result:
                    f.write(f"{result['message']}\n")
                    f.write(f"Accuracy: {result['accuracy']:.4f}\n")
                else:
                    f.write(f"Accuracy: {result['accuracy']:.4f}\n")
                    f.write(f"Precision: {result['precision']:.4f}\n")
                    f.write(f"Recall: {result['recall']:.4f}\n")
                    f.write(f"F1 Score: {result['f1_score']:.4f}\n")
                
                f.write("\n")
        
        print(f"üìÅ K·∫øt qu·∫£ ƒë√£ ƒë∆∞·ª£c l∆∞u t·∫°i: {summary_file}")


def select_images_for_ensemble():
    """Ch·ªçn ·∫£nh ƒë·ªÉ test ensemble"""
    print("\nüìÅ Ch·ªçn ·∫£nh ƒë·ªÉ test Ensemble System...")
    
    root = tk.Tk()
    root.withdraw()
    
    file_paths = filedialog.askopenfilenames(
        title="Ch·ªçn nhi·ªÅu ·∫£nh X-quang ƒë·ªÉ test ensemble",
        filetypes=[("Image files", "*.png *.jpg *.jpeg"), ("All files", "*.*")]
    )
    
    root.destroy()
    return list(file_paths)


def main():
    """Demo Multi-Region Ensemble System"""
    print("="*70)
    print("üöÄ MULTI-REGION ENSEMBLE FRACTURE DETECTION SYSTEM")
    print("="*70)
    
    try:
        # Kh·ªüi t·∫°o ensemble system
        print("üîÑ ƒêang kh·ªüi t·∫°o Ensemble System...")
        ensemble = MultiRegionEnsemble()
        
        if not ensemble.models:
            print("‚ùå Kh√¥ng t√¨m th·∫•y m√¥ h√¨nh n√†o ƒë·ªÉ t·∫°o ensemble!")
            return
        
        # Ch·ªçn ·∫£nh ƒë·ªÉ test
        test_images = select_images_for_ensemble()
        
        if not test_images:
            print("‚ùå Kh√¥ng c√≥ ·∫£nh n√†o ƒë∆∞·ª£c ch·ªçn!")
            return
        
        print(f"\nüìä ƒê√£ ch·ªçn {len(test_images)} ·∫£nh ƒë·ªÉ test")
        
        # Ch·ªçn ph∆∞∆°ng ph√°p voting
        print("\nüó≥Ô∏è Ch·ªçn ph∆∞∆°ng ph√°p voting:")
        print("1. Weighted Average (khuy·∫øn ngh·ªã)")
        print("2. Majority Vote")
        print("3. Max Confidence")
        print("4. T·∫•t c·∫£ ph∆∞∆°ng ph√°p")
        
        choice = input("Nh·∫≠p l·ª±a ch·ªçn (1-4): ").strip()
        
        voting_methods_map = {
            '1': ['weighted_average'],
            '2': ['majority_vote'],
            '3': ['max_confidence'],
            '4': ['weighted_average', 'majority_vote', 'max_confidence']
        }
        
        voting_methods = voting_methods_map.get(choice, ['weighted_average'])
        
        # Ch·∫°y evaluation
        print(f"\nüîÑ B·∫Øt ƒë·∫ßu ƒë√°nh gi√° v·ªõi {len(voting_methods)} ph∆∞∆°ng ph√°p voting...")
        
        results = ensemble.evaluate_ensemble(
            test_images, 
            voting_methods=voting_methods,
            visualize=True,
            output_dir='ensemble_evaluation_results'
        )
        
        # Hi·ªÉn th·ªã k·∫øt qu·∫£
        print(f"\n{'='*70}")
        print("üìä K·∫æT QU·∫¢ ENSEMBLE EVALUATION")
        print(f"{'='*70}")
        
        for method, result in results.items():
            print(f"\nüó≥Ô∏è Voting Method: {method.upper()}")
            print("-" * 40)
            
            if 'message' in result:
                print(f"   {result['message']}")
                print(f"   Accuracy: {result['accuracy']:.4f}")
            else:
                print(f"   üìà Accuracy:  {result['accuracy']:.4f}")
                print(f"   üéØ Precision: {result['precision']:.4f}")
                print(f"   üîç Recall:    {result['recall']:.4f}")
                print(f"   ‚öñÔ∏è F1 Score:  {result['f1_score']:.4f}")
        
        print(f"\n{'='*70}")
        print("‚úÖ Ensemble evaluation ho√†n t·∫•t!")
        print("üìÅ Chi ti·∫øt k·∫øt qu·∫£ ƒë∆∞·ª£c l∆∞u trong th∆∞ m·ª•c 'ensemble_evaluation_results/'")
        print(f"{'='*70}")
        
    except Exception as e:
        print(f"‚ùå L·ªói: {str(e)}")


if __name__ == "__main__":
    main()